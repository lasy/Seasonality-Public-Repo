---
title: "App data processing and filtering"
author: "Laura Symul - Micaela Martinez"
date: "last update: `r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2: 
    theme: cosmo
    highlight: haddock
    toc: yes
    toc_float: true
    toc_depth: 5
    number_sections: true
    fig_caption: true
---

```{r data_prep_clue setup, include = FALSE, eval = TRUE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
source("Scripts/00_setup.R")
```

# App (Clue) data processing and filtering {#dataprepclue}

## Dataset structure

The Clue dataset was provided in four tables:

- `users`: basic demographic information about the users.
    
- `birth_control`: users' birth control method as self-reported by users in their app profile. The table holds the type of birth control and the date at which they changed this option if they changed it. If they did not change their birth control in their app profile, the table provides the birth control self-reported by users when their first registered their app profile.
    
- `cycles` : cycles starts and ends. Provided in 20 files to keep each file at a reasonable size.
    
- `tracking` : time-series of the features tracked by the users. Provided in 20 files to keep each file at a reasonable size.
    
These tables were provided by Clue in `csv` files and we transformed into `feather` files (see package `feather`) to accelerate reading/writing operations.

## Filtering for countries/areas of interest.

Each of the four tables are filtered so that they only contain the data for users of the six countries/areas of interest: 

`r dict$country_area$country_area`


```{r child = '2b_filtering_for_country_area_US_BR_FR_UK.Rmd', cache=TRUE}
```

\newpage

## Dataset overview

__User table__

```{r data_prep_clue data overview users}
users = read_feather(path = paste0(IO$input_clue,"users.feather"))
```

The `users` table has `r nrow(users)` rows (_i.e._ users) and `r ncol(users)` columns: `r colnames(users)`


```{r data-prep-clue-data-overview-users-table-country}
df = table(country_area = users$country_area) %>% sort(decreasing = TRUE) %>% as.data.frame()
knitr::kable(df, format = "pandoc", caption = "Total number of app users in each area.")
```




```{r data-prep-clue-number-of-users-per-area, fig.width=6, fig.height=1.8, fig.cap = "Total number of users in each considered area"}

df = df %>%  mutate(
  country_area_col = dict$country_area$country_area_col[match(country_area, dict$country_area$country_area)],
  country_area_wrapped = str_replace(country_area," - ","\n") %>% factor(.,levels = str_replace(dict$country_area$country_area," - ","\n"))
)
ggplot(df, aes(x = country_area_wrapped, y = Freq, fill = country_area_col))+
  geom_bar(stat = "identity")+
  xlab("")+ylab("Total # of users")+
  scale_fill_identity()

```



```{r data-prep-clue-data-overview-users-birth-year-country}

kable(table(birth_year_bin = users$birth_year_bin) %>% as.data.frame(), 
      format = "pandoc", caption = "Total number of app users in each birth year bin")

```





__Birth control table__

```{r data_prep_clue data overview birth_control}

birth_control = read_feather(path = paste0(IO$input_clue,"birth_control.feather"))

```

The birth control table (`birth_control`) has `r nrow(birth_control)` rows (i.e. birth control at on-boarding and changes in birth control as declared by the users in their app profile) and `r ncol(birth_control)` columns:

`r colnames(birth_control)`

```{r data-prep-clue-data-overview-birth-control-table }

table(birth_control = birth_control$birth_control, useNA = "ifany") %>%  
  sort(decreasing = TRUE) %>% as.data.frame() %>% 
  kable(., format = "pandoc", caption = "Number of times users declared the following birth control in their app profile")

```

```{r data-prep-clue-data-overview-birth-control-table-viz, fig.height=10, fig.width=8, fig.caption = "Birth control changes over time."}

ggplot(
  birth_control %>% 
    group_by(date, birth_control) %>% 
    summarize(n = n(), .groups = "drop") %>% 
    left_join(., dict$BC_all %>% select(birth_control, type), by = "birth_control"),
  aes(x = date, y = n, col = birth_control)
) +
  geom_line() +
  facet_grid(type + birth_control ~ . , scale = "free") +
  guides(col = FALSE)  +
  theme(strip.text.y = element_text(angle = 0, hjust = 0))
  
```


__Cycle table__

The `cycles` table is split in several files due to their large size. Here, we load one the these files and describe the dataset based on this file.

```{r data_prep_clue data overview cycles}

cycles_00 = read_feather(path = paste0(IO$input_clue,"cycles/cycles0000.feather"))

```

The `cycles` tables have the following `r ncol(cycles_00)` columns:

`r colnames(cycles_00)`


This `cycles` file has a total of `r nrow(cycles_00)` cycles for `r length(unique(cycles_00$user_id))` users.

If we extrapolate from this number, we expect the total number of cycles to be 20 x `r nrow(cycles_00)` = `r format(nrow(cycles_00) * 20, scientific = FALSE)`.


```{r data-prep-clue-cycle-length-histogram, fig.height = 2, fig.width = 5, fig.cap= "Histogram of the cycle lengths"}
ggplot(cycles_00, aes(x = cycle_length))+
  geom_histogram(binwidth = 1)+ xlab("cycle length")+
  scale_x_continuous(breaks = seq(0,98, by = 7), limits = c(0,98))
```

Note that the `cycles` table is not further used in this analysis as the sex logs were aggregated at the population level, independent of the cycles in which they were logged.


__Tracking table__

The `tracking` table holds the daily logs of the app users.

```{r data_prep_clue data overview tracking}

tracking_folder = paste0(IO$input_clue,"tracking/")
files = list.files(tracking_folder)

tracking = read_feather(path = paste0(tracking_folder,files[1]))

```

The `tracking` table has `r ncol(tracking)` columns:

`r colnames(tracking)`.

Similarly to the `cycles` table, the `tracking` table is split into 20 files to keep each file at a reasonable size.

This particular files has `r nrow(tracking)` rows. If we extrapolate for the number of files, that means `r nrow(tracking) * 20` total logs.


The tracking features are grouped into categories (each category has max 4 items, which are displayed together on the logging screen of the App).

Based on this particular file, the frequency of each of these category goes as follow:


```{r data-prep-clue-data-overview-tracking, echo = FALSE}

(table(category = tracking$category) * 20 )%>%  
  sort(decreasing = TRUE) %>% 
  as.data.frame() %>% 
  kable(., format = "pandoc", caption = "Number of times each category has been logged by users (based on 1/20 file of the `tracking` table)")

```



Given that Clue did not provide data for all the tracking option they offer in the app, they additionally provided a "ANY" category, which tells us if anything was tracked in the app on that day. Note that for the categories displayed in the table above, all tracking data were provided, but some categories of the App, such as "doctor appointment" or "party" were not included in the dataset provided to the research team.

In section \@ref(userstimeseriesexamples), we provide examples of users' time-series.



## Data processing and filtering: WORKFLOW


- `users` table data augmentation (1)

    * split Country and Area into two distinct columns

    * estimate BMI from the weight and height bins

- Defining user batches: the `tracking` files provided by Clue did not ensure that the whole time-series of a user was held in a single file. Each user was thus assigned to a batch and the tracking table files are re-organized such that each file would contain the full time-series of users of a given batch. 
The users' features are also added to the tracking table at this step.

- `users` table data augmentation (2) : information from the `tracking` table is aggregated at the user level and added to the `users` table. 

    * Dates of their first and last log in the app
    
    * Number of days they logged features in the app 
    
    * Total number of logs
    
    * Total number of sex logs

- Label user's time-series (`tracking` table) with their __birth control__ (from the `birth_control` table).

- Label user's time-series (`tracking` table) as __active__ or __not active__. A user was considered active if they logged any feature in the app in a 42-day window. If that was the case, they were considered active for the whole 42-day window. 42 was chosen from 42 = 1.5*28, with 28 being the mode of cycle length distribution.



## Users table data augmentation (1)


```{r data_prep_clue countries}
countries_areas = users$country_area %>% str_split_fixed(., " - ", n = 2)
users$country = countries_areas[,1]
users$area = countries_areas[,2]

write_feather(users, path = paste0(IO$output_clue, "users.feather"))

```


```{r data_prep_clue BMI}

users$height_bin = factor(users$height_bin, levels = dict$height$bin)
users$weight_bin = factor(users$weight_bin, levels = dict$weight$bin)
heigh_mean = dict$height$mean[match(users$height_bin,dict$height$bin)]
weight_mean = dict$weight$mean[match(users$weight_bin,dict$weight$bin)]
users$est_mean_bmi = weight_mean/((heigh_mean/100)^2)

write_feather(users, path = paste0(IO$output_clue, "users.feather"))

```


```{r data-prep-clue-BMI-histogram, out.height='6cm', fig.cap = "Histogram of the user's estimated BMI for each country/area. For each user, their BMI is estimated based on their 5kg-weight and 5cm-height bins."}

ggplot(users, aes(x = est_mean_bmi))+
  geom_histogram(binwidth = 2)+
  facet_grid(country_area ~ ., scale = "free_y")+
  theme(strip.text.y = element_text(angle = 0, hjust = 0),
        strip.background.y = element_rect(fill = "gray90", color = NA))

```


## Defining user batches


```{r data_prep_clue defining the batches}

# maximum number of users per batch
max_batch_size = 5000 

# computing the number of batches given the total number of users and the minimum number of batches.
n_batch = max(par$min_n_batches, ceiling(nrow(users)/max_batch_size)) 

# effective batch size
batch_size = ceiling(nrow(users)/n_batch) 

users$batch = rep(1:n_batch, each = batch_size)[1:nrow(users)] # assigning a batch to each user
write_feather(users, path = paste0(IO$output_clue, "users.feather"))
ok = file.copy(from = paste0(IO$output_clue, "users.feather"), to = paste0(IO$tmp_clue, "users_with_batches.feather"))

```


```{r data_prep_clue filtering tracking tables by batches}

# for each tracking file:
#   we read it, 
#   assign each user to its batch
#   for each batch present in this file, we split the original tracking file and write them separately on disk
# for each user, we keep in the user table, the names of the original files in which its data were contained. 
# Most users only have 1 file, but some can have many.


tracking_folder = paste0(IO$input_clue,"tracking/")
files = list.files(tracking_folder)

tmp_folder = paste0(IO$tmp_clue,"tracking_split_in_batches/")
tmp_final_folder = paste0(IO$tmp_clue,"tracking_in_batches/")


# Given its long execution time, we only execute this code if the folder in which the splitted files by batch are stored does NOT exist. 
# To reset, one needs to "manually" delete the folder.
if((!file.exists(tmp_final_folder)) & (!file.exists(tmp_folder))){ 
  dir.create(tmp_folder,recursive = TRUE)
  
  cl = makeCluster(par$n_cores)
  registerDoParallel(cl)
  
  tic()
  users_original_file_ids = foreach(file = files, .combine = rbind, .packages = c("feather","stringr")) %dopar%
  {
    tracking = read_feather(path = paste0(tracking_folder, file))
    dim(tracking)
    tracking$batch = users$batch[match(tracking$user_id, users$user_id)]
    if(nrow(tracking)>0){
      for(b in unique(tracking$batch)){
        tracking_batch = tracking[which(tracking$batch == b),]
        new_file_name = gsub(".feather",paste0("_batch_",b,".feather"),file)
        write_feather(tracking_batch, path = paste0(tmp_folder, new_file_name ))
      }
      users_original_file_ids = data.frame(user_id = unique(tracking$user_id), original_file_id = str_extract(file,"\\d{4}"))
    }else{  users_original_file_ids = data.frame(user_id = character(), original_file_id = character())}
    return(users_original_file_ids)
  }
  toc()
  stopImplicitCluster()
  
  users_o_f = aggregate(original_file_id ~ user_id ,users_original_file_ids, function(x)  paste0(sort(x), collapse = ","))
  colnames(users_o_f) = c("user_id","original_tracking_files")
  write_feather(users_o_f, path = paste0(IO$tmp_clue,"original_tracking_files_per_users.feather"))
}else{
  warning("App data processing: spliting in batches is NOT done at this execution. Re-using results from a previous execution.")
}

```


```{r data_prep_clue re-assembling the batches together}

input_folder = paste0(IO$tmp_clue,"tracking_split_in_batches/")
output_folder = paste0(IO$output_clue,"tracking/")

# Similarly, we only execute this code if the folder does not exist.
# To re-execute this code, one needs to "manually" delete the folder.
if(!dir.exists(tmp_final_folder)){
  dir.create(tmp_final_folder,recursive = TRUE)
  
  # First we delete any existing tracking files in the output folder to avoid mess.
  if(file.exists(output_folder)){unlink(output_folder, recursive = TRUE)} ;dir.create(output_folder,recursive = TRUE)
  
  batches = unique(users$batch)
  ok = foreach(b = batches) %do% {
    cat("\t",b,"||\t")
    all_files = list.files(input_folder)
    files = all_files[grep(paste0("_batch_",b,"\\."),all_files)]
    
    cl = makeCluster(par$n_cores)
    registerDoParallel(cl)
    tracking = foreach(file  = files, .combine = rbind, .packages = "feather") %dopar%{tracking = read_feather(path = paste0(input_folder, file));return(tracking)}
    stopImplicitCluster()
    
    cols_to_add = c("birth_year_bin","country_area","height_bin","weight_bin", "est_mean_bmi")
    m = match(tracking$user_id, users$user_id)
    for(col_to_add in cols_to_add){
      eval(parse(text = paste0("tracking$",col_to_add," = users$",col_to_add,"[m]")))
    }
    o = order(tracking$user_id, tracking$date, tracking$category, tracking$type, tracking$number)
    tracking = tracking[o,]
    
    new_file_name = paste0("tracking_",b,".feather")
    write_feather(tracking, path = paste0(output_folder, new_file_name ))
    ok = file.copy(from = paste0(output_folder, new_file_name ), to = paste0(tmp_final_folder, new_file_name), overwrite = TRUE)
  }
}else{
  warning("App data processing: re-assembling in batches is NOT done at this execution. Re-using results from a previous execution.")
}

```


## Users table data augmentation (2)

Information from the `tracking` table is aggregated at the user level and added to the `users` table: 

    * Dates of their first and last log in the app
    
    * Number of days they logged features in the app 
    
    * Total number of logs
    
    * Total number of sex logs


```{r data_prep_clue aggregating key tracking info at the users level}

if(!file.exists(paste0(IO$tmp_clue, "users_agg.feather"))){
  
  tracking_folder = paste0(IO$output_clue,"tracking/")
  files = list.files(tracking_folder)
  
  cl = makeCluster(par$n_cores)
  registerDoParallel(cl)
  
  tic()
  users_agg = foreach(file = files, .combine = rbind, .packages = c("feather","stringr", "plyr")) %dopar%
  {
    tracking = read_feather(path = paste0(tracking_folder, file))
    users_agg = ddply(tracking,
                      .(user_id),
                      summarize,
                      first_obs = min(date),
                      last_obs = max(date),
                      n_obs_day = length(unique(date)),
                      n_obs = sum(category != "ANY"),
                      n_sex = sum(category == "sex"),
                      n_mucus =  sum(category == "fluid"),
                      n_temp = sum(category == "bbt")
    )
    return(users_agg)
  }
  toc()
  stopImplicitCluster()
  
  write_feather(users_agg, path = paste0(IO$tmp_clue, "users_agg.feather"))
  
}else{
  warning("App data processing: tracking aggregation at the user level is NOT done at this iteration. Re-using results from a previous execution.")
}

```

```{r data_prep_clue augmenting the users table}

users_agg = read_feather(path = paste0(IO$tmp_clue, "users_agg.feather"))

cols_to_add = setdiff(colnames(users_agg),"user_id")
m = match(users$user_id, users_agg$user_id)
for(col_to_add in cols_to_add){eval(parse(text = paste0("users$",col_to_add," = users_agg$",col_to_add,"[m]")))}
users$n_days = as.numeric(users$last_obs - users$first_obs)

write_feather(users, path = paste0(IO$output_clue, "users.feather"))
ok = file.copy(from = paste0(IO$output_clue, "users.feather"), to = paste0(IO$tmp_clue, "users_augmented.feather"))
```



## Users birth control

In this section, we label the user's time-series (`tracking` table) with the __birth control__ the user declared in their app profile (from the `birth_control` table). If a user changed birth control (and thus have multiple entries at different dates in the `birth_control` table), their time-series are labeled with these different birth control.

Note that the birth control feature was introduced into the app around April 2017. Thus users who started tracking with the app before that date do not have an entry for their data before that date. In addition, some users do not declare their birth control at on-boarding but do so later. Altogether, when birth control information is missing, it is replaced by "undefined".


```{r data_prep_clue birth_control table}

BC = birth_control
BC = BC %>% 
  arrange(user_id, date) %>% 
  mutate(birth_control = birth_control %>% replace_na("undefined"))

write_feather(BC, path = paste0(IO$output_clue, "birth_control.feather"))

```


```{r data_prep_clue adding birth_control table to tracking table}

BC = read_feather(path = paste0(IO$output_clue,"birth_control.feather"))

input_folder = paste0(IO$tmp_clue,"tracking_in_batches/")
output_folder = paste0(IO$output_clue,"tracking/")
tmp_folder = paste0(IO$tmp_clue, "tracking_with_user_defined_birth_control/")

if(!dir.exists(tmp_folder)){
  
  dir.create(tmp_folder)
  files = list.files(input_folder)
  
  cl = makeCluster(par$n_cores)
  registerDoParallel(cl)
  
  tic()
  catch = 
    foreach(file = files, 
            .combine = rbind, 
            .packages = c("feather","stringr", "plyr","tidyverse")
    ) %dopar% {
      
      tracking = read_feather(path = paste0(input_folder, file))

      # creating a table (BC_exp) that has one row per user and date that is found either in the tracking table or in the BC table. This table thus have one row per user and date
        BC_exp = full_join(
          BC %>% 
            filter(user_id %in% unique(tracking$user_id)) %>% 
            select(-csv_file, -pill_type, -pill_regiment) %>% 
            distinct(),
          tracking %>% 
            select(user_id, date) %>% 
            distinct(),
          by = c("user_id", "date")
        ) %>% 
        arrange(user_id, date, birth_control) %>% 
        group_by(user_id) %>% 
        mutate(
          birth_control = 
            replace_NAs_with_latest_value(birth_control) %>% 
            replace_na("undefined")
        )
      
      tracking = tracking %>% 
        left_join(.,
                  BC_exp, 
                  by = c("user_id", "date"))
      
      write_feather(tracking, path = paste0(output_folder,file))
      file.copy(from = paste0(output_folder,file), to = paste0(tmp_folder,file), overwrite = TRUE)
    }
  toc()
  stopImplicitCluster()
}else{
  warning("App data processing: adding birth control to tracking table is NOT done at this execution. Re-using results from a previous execution.")
}

```


## Identifying active use of the app

User's time-series (`tracking` table) are labeled with __active__ or __not active__ labels. A user was considered active if they open and logged any feature in the app twice in a 42-day window. If that was the case, they were considered active for the whole 42-day window. 42 was chosen from 42 = 1.5*28, with 28 being the mode of cycle length distribution. A user can transition several times between "active" and "inactive" use of the App.


```{r data_prep_clue users active tracking periods }

input_folder = paste0(IO$output_clue,"tracking/")
files = list.files(input_folder)

output_folder = paste0(IO$tmp_clue, "active_tracking/")
if(!dir.exists(output_folder)){
  
  dir.create(output_folder)
  
  time_vec = seq(min(users$first_obs), max(users$last_obs), by = 1)
  
  cl = makeCluster(par$n_cores)
  registerDoParallel(cl)
  tic()
  ok = 
    foreach(file = files, 
            .packages = c("dplyr", "feather", "tidyr")) %dopar% 
    {
      # we load the tracking table
      tracking = read_feather(path = paste0(input_folder, file)) 
      
      # we keep the dates at which users logged smth in the app
      any_tracking = tracking %>% filter(. , category == "ANY")  %>% 
        select(user_id, date, birth_control) %>% 
        mutate(tracking_days = 1)
      
      # we create a data.frame that has one row for each calendar day from the first to the last log
      tmp = expand_grid(
        user_id = unique(tracking$user_id), 
        date = time_vec)
      
      # we join this tmp table with the table that has active tracking.
      active_tracking = full_join(tmp,any_tracking, by = c("user_id","date"))

      # tracking_days is zero when there were no entries in the tracking table
      active_tracking = active_tracking %>%  
        mutate(tracking_days = tracking_days %>% replace_na(0))
      # we keep the BC info
      active_tracking = active_tracking %>% 
        group_by(user_id) %>% 
        mutate(birth_control = birth_control %>% replace_NAs_with_latest_value)
      # we check for any active tracking in 42 days window
      active_tracking = active_tracking %>%  group_by(user_id) %>%  
        mutate(tracking = data.table::frollsum(tracking_days,
                                               fill = 0,
                                               n = 42, 
                                               align = "right") >= 2)

      # only keep the necessary columns.
      active_tracking = active_tracking %>% 
        select(user_id, date, birth_control, tracking)
      
      ###
      # compressed table 
      # (we compress the active tracking table to speed up IO operations)
      active_tracking  = active_tracking %>%  
        group_by(user_id, birth_control) %>% 
        mutate(transition = diff(c(0, tracking))) %>%  
        group_by(user_id) %>% 
        mutate(stretch_num = cumsum(transition == 1)) %>%  
        group_by(user_id, birth_control, stretch_num, tracking) %>%  
        mutate(stretch_length = sum(tracking)) %>% 
        ungroup()
      
      compressed_tracking = active_tracking %>% filter(transition == 1) %>%  
        select(user_id, date, birth_control, stretch_num, stretch_length) %>%  
        dplyr::rename(start_date = date)
      
      file_name = paste0("active_",file)
      write_feather(compressed_tracking, path = paste0(output_folder,file_name))
    }
  toc()
  stopImplicitCluster()
  
}else{
  warning("App data processing: identification of active use is NOT done at this execution. Re-using results from a previous execution.")
}

```


## Examples of individual users time-series {#userstimeseriesexamples}


```{r data_prep_clue examples of users timeseries loading data}

input_folder = paste0(IO$output_clue,"tracking/")
files = list.files(input_folder)
file = files[1]

tracking = read_feather(path = paste0(input_folder, file)) # we load the tracking table
```

```{r data_prep_clue user time series plotting function}

plot_user_timeseries = function(tracking, u){
  
  dat = tracking %>% filter(user_id == u) %>%
    mutate(rel_date = (date - min(date)) %>% as.numeric()) %>%
    arrange(rel_date) %>% 
    mutate(category = factor(category, levels = c("ANY", unique(feature_dict$category) %>% as.character())),
           type_col = feature_dict$color[match(type, feature_dict$type)] %>%  replace_na("black"))
  
  g = ggplot(dat, aes(x = rel_date, y = type, col = type_col))
  g = g +
    geom_point()+
    xlab("days from 1st log in the App")+ ylab("")+
    scale_color_identity()+
    facet_grid(category ~ ., scale = "free_y", space = "free", switch = "y")+
    theme(strip.placement = "outside",
          strip.background.y = element_rect(fill = "gray80", color = NA),
          strip.text.y.left = element_text(angle = 0, hjust = 1))
  g
  
}

```



```{r data-prep-clue-example1, fig.width=7, fig.height=2, fig.cap="Example of a user tracking time-series (1)"}

u = c("dd1de61df75ded8f4dbbb0be30f27d2b8c658b4f")

plot_user_timeseries(tracking = tracking, u = u)


```

```{r data-prep-clue-example2, fig.width=7, fig.height= 4.5, fig.cap="Example of a user tracking time-series (2)"}
# u = sample(tracking$user_id, 1)
# u = "b2f86085f009a8d1bc9691b782b6ffc1308871af"
u = "e12d958dc494c3c2a3aa2d42be6683f96bdd90e7"

plot_user_timeseries(tracking = tracking, u = u)

```


## Dataset characteristics

```{r data-prep-clue-tracking-stat}

# Directory with the tracking tables
input_folder = paste0(IO$output_clue,"tracking/")
files = list.files(input_folder)

# Directory with the active tracking tables
input_active_tracking = paste0(IO$tmp_clue,"active_tracking/")

# file on which the tracking_duration_stats are saved
tds_file = str_c(IO$tmp_clue, "tracking_duration_stats.feather")

if(!file.exists(tds_file)){
  
  tracking_duration_stats = purrr::map_dfr(
    files, 
    .f = function(file){
      tracking = read_feather(str_c(input_folder, file))
      active_tracking =  read_feather(str_c(input_active_tracking, "active_", file))
      data.frame(file = file, 
                 number_of_days_of_observation = tracking %>% select(user_id, date) %>% distinct() %>% nrow(),
                 total_duration_of_active_tracking = active_tracking$stretch_length %>% sum())
    })
  write_feather(tracking_duration_stats, path = tds_file)
}else{
  tracking_duration_stats = read_feather(path = tds_file)
}

tracking_duration_stats_summary = tracking_duration_stats %>% 
  summarise(number_of_days_of_observation = sum(number_of_days_of_observation),
            total_duration_of_active_tracking_in_days = sum(total_duration_of_active_tracking)) %>% 
  mutate(number_of_years_of_observation = number_of_days_of_observation/365,
         total_duration_of_active_tracking_in_years = total_duration_of_active_tracking_in_days/365)

```

```{r data-prep-clue-tracking-stat-tab}

kable(t(tracking_duration_stats_summary),
      format = "latex",
      booktabs = T,
      caption = "Total duration of active tracking and number of days tracked in the app.")

```



